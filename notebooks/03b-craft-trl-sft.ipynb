{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03b Â· CRAFT with TRL SFTTrainer\n",
        "\n",
        "This notebook mirrors the TRL SFT workflow while adding the CRAFT objective.\n",
        "It now formats conversations with `tokenizer.apply_chat_template` so only assistant\n",
        "tokens contribute to the supervised loss, and it highlights the new length-handling\n",
        "options for mixed SFT / contrastive dataloaders.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Optional environment setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -U \"contrastive-ft[trl] @ git+https://github.com/omarkamali/craft\"\n",
        "# !pip install -U \"datasets>=2.19\" \"transformers>=4.43\" \"trl>=0.9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from craft.config import CRAFTSFTConfig\n",
        "from craft.data import CRAFTCollator, make_craft_datasets\n",
        "from craft.trainers import CRAFTSFTTrainer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Tokeniser helpers with chat template\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_LENGTH = 1024\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def encode_chat(example):\n",
        "    encoded = tokenizer.apply_chat_template(\n",
        "        example[\"messages\"],\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=False,\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True,\n",
        "        return_assistant_tokens_mask=True,\n",
        "    )\n",
        "    input_ids = encoded[\"input_ids\"][0]\n",
        "    attention_mask = encoded[\"attention_mask\"][0]\n",
        "    assistant_mask = encoded[\"assistant_masks\"][0]\n",
        "    labels = input_ids.clone().masked_fill(assistant_mask == 0, -100)\n",
        "    return {\n",
        "        \"input_ids\": input_ids.tolist(),\n",
        "        \"attention_mask\": attention_mask.tolist(),\n",
        "        \"labels\": labels.tolist(),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load conversational slices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sft_raw = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train[:0.3%]\")\n",
        "tokenized_sft = sft_raw.map(encode_chat, remove_columns=sft_raw.column_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Bundle & collator (self-align)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bundle = make_craft_datasets(tokenized_sft, strategy=\"self_align\")\n",
        "collator = CRAFTCollator()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load base model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
        "model.config.use_cache = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Trainer configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = CRAFTSFTConfig(\n",
        "    output_dir=\"./outputs/craft-trl-sft\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=12,\n",
        "    learning_rate=1.5e-5,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=5,\n",
        "    save_steps=50,\n",
        "    craft_alpha=0.65,\n",
        "    craft_beta=0.5,\n",
        "    craft_beta_mode=\"auto\",\n",
        "    craft_length_strategy=\"auto_beta\",\n",
        "    craft_pooling=\"mean\",\n",
        "    craft_report_metrics=[\"contrastive_accuracy\", \"representation_consistency\"],\n",
        ")\n",
        "\n",
        "trainer = CRAFTSFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_sft,\n",
        "    data_collator=collator,\n",
        "    craft_bundle=bundle,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Inspect metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.craft_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save weights & tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"./outputs/craft-trl-sft\")\n",
        "tokenizer.save_pretrained(\"./outputs/craft-trl-sft\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
