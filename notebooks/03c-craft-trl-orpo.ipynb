{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7dbbb0ee",
      "metadata": {},
      "source": [
        "# 03c Â· CRAFT with TRL ORPOTrainer\n",
        "\n",
        "This notebook adapts ORPO preference optimisation to include the CRAFT contrastive objective.\n",
        "Conversations are formatted with `tokenizer.apply_chat_template`, enabling assistant-only\n",
        "loss masking via `return_assistant_tokens_mask`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8151d2f",
      "metadata": {},
      "source": [
        "## 0. Optional environment setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e12c5e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -U \"contrastive-ft[trl] @ git+https://github.com/omarkamali/craft\"\n",
        "# !pip install -U \"datasets>=2.19\" \"transformers>=4.43\" \"trl>=0.9\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d8af53",
      "metadata": {},
      "source": [
        "## 1. Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0dcaa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from craft.config import CRAFTORPOConfig\n",
        "from craft.data import CRAFTCollator, make_craft_datasets\n",
        "from craft.trainers import CRAFTORPOTrainer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "494aac5b",
      "metadata": {},
      "source": [
        "## 2. Tokeniser and helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "749ad4d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_LENGTH = 768\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "def to_messages(prompt: str, response: str):\n",
        "    prompt = prompt or \"\"\n",
        "    return [\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "    ]\n",
        "\n",
        "\n",
        "def encode_response(prompt: str, response: str):\n",
        "    encoded = tokenizer.apply_chat_template(\n",
        "        to_messages(prompt, response),\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=False,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True,\n",
        "        return_assistant_tokens_mask=True,\n",
        "    )\n",
        "    input_ids = encoded[\"input_ids\"][0]\n",
        "    attention_mask = encoded[\"attention_mask\"][0]\n",
        "    assistant_mask = encoded[\"assistant_masks\"][0]\n",
        "    labels = input_ids.clone().masked_fill(assistant_mask == 0, -100)\n",
        "    return (\n",
        "        input_ids.tolist(),\n",
        "        attention_mask.tolist(),\n",
        "        labels.tolist(),\n",
        "        assistant_mask.tolist(),\n",
        "    )\n",
        "\n",
        "\n",
        "def encode_pref(example):\n",
        "    prompt = example.get(\"context\", \"\")\n",
        "    chosen = example[\"chosen_response\"]\n",
        "    rejected = example[\"rejected_response\"]\n",
        "\n",
        "    chosen_ids, chosen_attn, chosen_labels, chosen_mask = encode_response(prompt, chosen)\n",
        "    rejected_ids, rejected_attn, rejected_labels, rejected_mask = encode_response(prompt, rejected)\n",
        "    prompt_ids, prompt_attn, _, _ = encode_response(prompt, \"\")\n",
        "\n",
        "    return {\n",
        "        \"prompt_input_ids\": prompt_ids,\n",
        "        \"prompt_attention_mask\": prompt_attn,\n",
        "        \"chosen_input_ids\": chosen_ids,\n",
        "        \"chosen_attention_mask\": chosen_attn,\n",
        "        \"chosen_labels\": chosen_labels,\n",
        "        \"chosen_assistant_mask\": chosen_mask,\n",
        "        \"rejected_input_ids\": rejected_ids,\n",
        "        \"rejected_attention_mask\": rejected_attn,\n",
        "        \"rejected_labels\": rejected_labels,\n",
        "        \"rejected_assistant_mask\": rejected_mask,\n",
        "    }\n",
        "\n",
        "\n",
        "def encode_contrastive(example):\n",
        "    anchor_tokens = tokenizer(\n",
        "        example[\"premise\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    positive_tokens = tokenizer(\n",
        "        example[\"hypothesis\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": anchor_tokens[\"input_ids\"][0].tolist(),\n",
        "        \"attention_mask\": anchor_tokens[\"attention_mask\"][0].tolist(),\n",
        "        \"input_ids_tgt\": positive_tokens[\"input_ids\"][0].tolist(),\n",
        "        \"attention_mask_tgt\": positive_tokens[\"attention_mask\"][0].tolist(),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8bb3247",
      "metadata": {},
      "source": [
        "## 3. Load datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbaa1269",
      "metadata": {},
      "outputs": [],
      "source": [
        "pref_raw = load_dataset(\"Anthropic/hh-rlhf\", split=\"train[:0.2%]\")\n",
        "pref_raw = pref_raw.rename_columns({\"chosen\": \"chosen_response\", \"rejected\": \"rejected_response\"})\n",
        "tokenized_pref = pref_raw.map(encode_pref, remove_columns=pref_raw.column_names)\n",
        "\n",
        "contrastive_raw = load_dataset(\"sentence-transformers/all-nli\", split=\"train[:0.2%]\")\n",
        "tokenized_contrastive = contrastive_raw.map(\n",
        "    encode_contrastive, remove_columns=contrastive_raw.column_names\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da80e75",
      "metadata": {},
      "source": [
        "## 4. Bundle & collator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dabfae9",
      "metadata": {},
      "outputs": [],
      "source": [
        "bundle = make_craft_datasets(\n",
        "    tokenized_pref,\n",
        "    contrastive_dataset=tokenized_contrastive,\n",
        "    strategy=\"paired_dataset\",\n",
        ")\n",
        "collator = CRAFTCollator()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c7951b",
      "metadata": {},
      "source": [
        "## 5. Load model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edca56fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
        "model.config.use_cache = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bfa12ed",
      "metadata": {},
      "source": [
        "## 6. Configure trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2413c526",
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = CRAFTORPOConfig(\n",
        "    output_dir=\"./outputs/craft-trl-orpo\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=12,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=8e-6,\n",
        "    logging_steps=5,\n",
        "    save_steps=50,\n",
        "    craft_alpha=0.5,\n",
        "    craft_beta=0.4,\n",
        "    craft_beta_mode=\"auto\",\n",
        "    craft_length_strategy=\"oversample\",\n",
        "    craft_pooling=\"mean\",\n",
        ")\n",
        "\n",
        "trainer = CRAFTORPOTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_pref,\n",
        "    data_collator=collator,\n",
        "    craft_bundle=bundle,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4f2c0c",
      "metadata": {},
      "source": [
        "## 7. Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46f947d",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f57c8883",
      "metadata": {},
      "source": [
        "## 8. Inspect metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a606ac53",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.craft_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e713ef1",
      "metadata": {},
      "source": [
        "## 9. Save outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"./outputs/craft-trl-orpo\")\n",
        "tokenizer.save_pretrained(\"./outputs/craft-trl-orpo\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
