{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d293ef3f",
      "metadata": {},
      "source": [
        "# 04 · CRAFT QLoRA Translation Benchmark\n",
        "\n",
        "We compare a **base model**, an **SFT-only fine-tune**, and a **CRAFT fine-tune** on Flores translations.\n",
        "Every supervised batch is tokenised with `tokenizer.apply_chat_template(..., return_assistant_tokens_mask=True)`\n",
        "so loss is applied only on assistant tokens. The notebook also highlights the new length-matching options for\n",
        "mixed SFT / InfoNCE loading.\n",
        "\n",
        "> ⚠️ Expect GPU resources and non-trivial runtime. Adjust LoRA targets, batch sizes, and max steps for your setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1942cb",
      "metadata": {},
      "source": [
        "## 0. Environment setup\n",
        "Install requirements in your runtime if they're not already available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dfcf9f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -U \"contrastive-ft[all] @ git+https://github.com/omarkamali/craft\"\n",
        "# !pip install -U \"unsloth>=2024.9.0\" \"bitsandbytes>=0.43\" \"peft>=0.11\" \"accelerate>=0.30\" \"datasets>=2.19\" \"evaluate>=0.4\" \"matplotlib>=3.8\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7d027c2",
      "metadata": {},
      "source": [
        "## 1. Imports & experiment configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebadc94",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from matplotlib import pyplot as plt\n",
        "from transformers import AutoTokenizer, GenerationConfig\n",
        "\n",
        "from craft.config import CRAFTSFTConfig\n",
        "from craft.data import CRAFTCollator, make_craft_datasets\n",
        "from craft.trainers import CRAFTSFTTrainer\n",
        "\n",
        "BLEU = None\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    model_id: str = \"unsloth/gemma-3-270m-it\"\n",
        "    source_lang: str = \"eng_Latn\"\n",
        "    target_lang: str = \"spa_Latn\"\n",
        "    sft_train_size: int = 1024\n",
        "    contrastive_train_size: int = 1024\n",
        "    eval_size: int = 128\n",
        "    max_seq_length: int = 512\n",
        "    lora_r: int = 8\n",
        "    per_device_train_batch_size: int = 2\n",
        "    gradient_accumulation_steps: int = 16\n",
        "    learning_rate: float = 1.5e-4\n",
        "    sft_max_steps: int = 150\n",
        "    craft_max_steps: int = 200\n",
        "    craft_alpha: float = 0.6\n",
        "    craft_beta: float = 0.4\n",
        "    craft_beta_mode: str = \"auto\"\n",
        "    craft_length_strategy: str = \"auto_beta\"\n",
        "    craft_contrastive_batch_size: int = 4\n",
        "    eval_batch_size: int = 8\n",
        "    generation: GenerationConfig = field(\n",
        "        default_factory=lambda: GenerationConfig(max_new_tokens=128, temperature=0.7)\n",
        "    )\n",
        "    output_dir: Path = field(default_factory=lambda: Path(\"./outputs/craft-qlora\"))\n",
        "\n",
        "CFG = ExperimentConfig()\n",
        "CFG.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "torch.manual_seed(42)\n",
        "plt.style.use(\"seaborn-v0_8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "512121f3",
      "metadata": {},
      "source": [
        "## 2. Tokenizer & chat templating helpers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c20194",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(CFG.model_id)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def build_translation_messages(example):\n",
        "    source = example[f\"sentence_{CFG.source_lang}\"]\n",
        "    target = example[f\"sentence_{CFG.target_lang}\"]\n",
        "    return [\n",
        "        {\"role\": \"user\", \"content\": f\"Translate to {CFG.target_lang}: {source}\"},\n",
        "        {\"role\": \"assistant\", \"content\": target},\n",
        "    ]\n",
        "\n",
        "def encode_chat(messages):\n",
        "    encoded = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=False,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=CFG.max_seq_length,\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True,\n",
        "        return_assistant_tokens_mask=True,\n",
        "    )\n",
        "    input_ids = encoded[\"input_ids\"][0]\n",
        "    attention_mask = encoded[\"attention_mask\"][0]\n",
        "    assistant_mask = encoded[\"assistant_masks\"][0]\n",
        "    labels = input_ids.clone().masked_fill(assistant_mask == 0, -100)\n",
        "    return input_ids, attention_mask, assistant_mask, labels\n",
        "\n",
        "def tokenize_sft(example):\n",
        "    input_ids, attention_mask, assistant_mask, labels = encode_chat(build_translation_messages(example))\n",
        "    return {\n",
        "        \"input_ids\": input_ids.tolist(),\n",
        "        \"attention_mask\": attention_mask.tolist(),\n",
        "        \"labels\": labels.tolist(),\n",
        "        \"assistant_mask\": assistant_mask.tolist(),\n",
        "    }\n",
        "\n",
        "def tokenize_contrastive(example):\n",
        "    anchor = example[f\"sentence_{CFG.source_lang}\"]\n",
        "    positive = example[f\"sentence_{CFG.target_lang}\"]\n",
        "    anchor_tokens = tokenizer(\n",
        "        anchor,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=CFG.max_seq_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    positive_tokens = tokenizer(\n",
        "        positive,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=CFG.max_seq_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": anchor_tokens[\"input_ids\"][0].tolist(),\n",
        "        \"attention_mask\": anchor_tokens[\"attention_mask\"][0].tolist(),\n",
        "        \"input_ids_tgt\": positive_tokens[\"input_ids\"][0].tolist(),\n",
        "        \"attention_mask_tgt\": positive_tokens[\"attention_mask\"][0].tolist(),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb063f6",
      "metadata": {},
      "source": [
        "## 3. Load & tokenise Flores subsets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed248db1",
      "metadata": {},
      "outputs": [],
      "source": [
        "flores = load_dataset(\"facebook/flores\")\n",
        "\n",
        "train_sft_raw = flores[\"dev\"].select(range(CFG.sft_train_size))\n",
        "train_contrastive_raw = flores[\"devtest\"].select(range(CFG.contrastive_train_size))\n",
        "val_eval = flores[\"devtest\"].select(range(CFG.contrastive_train_size, CFG.contrastive_train_size + CFG.eval_size))\n",
        "\n",
        "train_sft = train_sft_raw.map(tokenize_sft, remove_columns=train_sft_raw.column_names)\n",
        "train_contrastive = train_contrastive_raw.map(\n",
        "    tokenize_contrastive, remove_columns=train_contrastive_raw.column_names\n",
        ")\n",
        "\n",
        "len(train_sft), len(train_contrastive), len(val_eval)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d603226c",
      "metadata": {},
      "source": [
        "## 4. Build dataset bundles & collator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02839703",
      "metadata": {},
      "outputs": [],
      "source": [
        "bundle_craft = make_craft_datasets(\n",
        "    train_sft,\n",
        "    contrastive_dataset=train_contrastive,\n",
        "    strategy=\"paired_dataset\",\n",
        ")\n",
        "bundle_sft_only = make_craft_datasets(train_sft, strategy=\"self_align\")\n",
        "collator = CRAFTCollator()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0009801e",
      "metadata": {},
      "source": [
        "## 5. Helper utilities (model loading, evaluation, cleanup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f55636",
      "metadata": {},
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "def load_qlora_model():\n",
        "    model, adapter_tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=CFG.model_id,\n",
        "        max_seq_length=CFG.max_seq_length,\n",
        "        load_in_4bit=True,\n",
        "        dtype=None,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    adapter_tokenizer.pad_token = adapter_tokenizer.eos_token\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r=CFG.lora_r,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    )\n",
        "    model.config.use_cache = False\n",
        "    return model, adapter_tokenizer\n",
        "\n",
        "def evaluate_bleu(model, tokenizer, dataset, *, max_examples: int):\n",
        "    global BLEU\n",
        "    if BLEU is None:\n",
        "        import evaluate as hf_evaluate\n",
        "        BLEU = hf_evaluate.load(\"sacrebleu\")\n",
        "\n",
        "    model.eval()\n",
        "    preds: List[str] = []\n",
        "    refs: List[List[str]] = []\n",
        "    subset = dataset.select(range(min(len(dataset), max_examples)))\n",
        "\n",
        "    for example in subset:\n",
        "        prompt = f\"Translate to {CFG.target_lang}: {example[f'sentence_{CFG.source_lang}']}\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.inference_mode():\n",
        "            generated = model.generate(**inputs, generation_config=CFG.generation)\n",
        "        decoded = tokenizer.decode(generated[0], skip_special_tokens=True).strip()\n",
        "        preds.append(decoded)\n",
        "        refs.append([example[f\"sentence_{CFG.target_lang}\"]])\n",
        "\n",
        "    bleu = BLEU.compute(predictions=preds, references=refs)[\"score\"]\n",
        "    return bleu, preds, refs\n",
        "\n",
        "def cleanup_model(model):\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81f92afe",
      "metadata": {},
      "source": [
        "## 6. Baseline evaluation (untrained adapters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf59b5e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "results: List[Dict[str, float]] = []\n",
        "predictions: Dict[str, Dict[str, List[str]]] = {}\n",
        "\n",
        "base_model, base_tokenizer = load_qlora_model()\n",
        "base_bleu, base_preds, base_refs = evaluate_bleu(\n",
        "    base_model, base_tokenizer, val_eval, max_examples=CFG.eval_size\n",
        ")\n",
        "results.append({\"label\": \"base\", \"bleu\": base_bleu})\n",
        "predictions[\"base\"] = {\"preds\": base_preds, \"refs\": base_refs}\n",
        "print(f\"Baseline sacreBLEU: {base_bleu:.2f}\")\n",
        "cleanup_model(base_model)\n",
        "del base_tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "242e741c",
      "metadata": {},
      "source": [
        "## 7. SFT-only fine-tuning (CRAFT disabled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da588e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "sft_model, sft_tokenizer = load_qlora_model()\n",
        "sft_args = CRAFTSFTConfig(\n",
        "    output_dir=str(CFG.output_dir / \"sft_only\"),\n",
        "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
        "    max_steps=CFG.sft_max_steps,\n",
        "    learning_rate=CFG.learning_rate,\n",
        "    logging_steps=10,\n",
        "    save_steps=CFG.sft_max_steps,\n",
        "    bf16=torch.cuda.is_available(),\n",
        "    craft_alpha=1.0,\n",
        "    craft_beta=1.0,\n",
        "    craft_length_strategy=\"error\",\n",
        "    craft_report_metrics=[\"contrastive_accuracy\"],\n",
        ")\n",
        "sft_trainer = CRAFTSFTTrainer(\n",
        "    model=sft_model,\n",
        "    args=sft_args,\n",
        "    train_dataset=train_sft,\n",
        "    data_collator=collator,\n",
        "    craft_bundle=bundle_sft_only,\n",
        ")\n",
        "sft_trainer.train()\n",
        "sft_bleu, sft_preds, sft_refs = evaluate_bleu(\n",
        "    sft_model, sft_tokenizer, val_eval, max_examples=CFG.eval_size\n",
        ")\n",
        "results.append({\"label\": \"sft_only\", \"bleu\": sft_bleu})\n",
        "predictions[\"sft_only\"] = {\"preds\": sft_preds, \"refs\": sft_refs}\n",
        "print(f\"SFT-only sacreBLEU: {sft_bleu:.2f}\")\n",
        "sft_trainer.save_model(str(CFG.output_dir / \"sft_only\"))\n",
        "sft_tokenizer.save_pretrained(str(CFG.output_dir / \"sft_only\"))\n",
        "cleanup_model(sft_model)\n",
        "del sft_tokenizer\n",
        "del sft_trainer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "907856e6",
      "metadata": {},
      "source": [
        "## 8. CRAFT fine-tuning with contrastive batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1613ba58",
      "metadata": {},
      "outputs": [],
      "source": [
        "craft_model, craft_tokenizer = load_qlora_model()\n",
        "craft_args = CRAFTSFTConfig(\n",
        "    output_dir=str(CFG.output_dir / \"craft\"),\n",
        "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
        "    max_steps=CFG.craft_max_steps,\n",
        "    learning_rate=CFG.learning_rate,\n",
        "    logging_steps=10,\n",
        "    save_steps=CFG.craft_max_steps,\n",
        "    bf16=torch.cuda.is_available(),\n",
        "    craft_alpha=CFG.craft_alpha,\n",
        "    craft_beta=CFG.craft_beta,\n",
        "    craft_beta_mode=CFG.craft_beta_mode,\n",
        "    craft_contrastive_batch_size=CFG.craft_contrastive_batch_size,\n",
        "    craft_length_strategy=CFG.craft_length_strategy,\n",
        "    craft_report_metrics=[\"contrastive_accuracy\", \"representation_consistency\"],\n",
        ")\n",
        "craft_trainer = CRAFTSFTTrainer(\n",
        "    model=craft_model,\n",
        "    args=craft_args,\n",
        "    train_dataset=train_sft,\n",
        "    data_collator=collator,\n",
        "    craft_bundle=bundle_craft,\n",
        ")\n",
        "craft_trainer.train()\n",
        "craft_bleu, craft_preds, craft_refs = evaluate_bleu(\n",
        "    craft_model, craft_tokenizer, val_eval, max_examples=CFG.eval_size\n",
        ")\n",
        "results.append({\"label\": \"craft\", \"bleu\": craft_bleu})\n",
        "predictions[\"craft\"] = {\"preds\": craft_preds, \"refs\": craft_refs}\n",
        "print(f\"CRAFT sacreBLEU: {craft_bleu:.2f}\")\n",
        "craft_trainer.save_model(str(CFG.output_dir / \"craft\"))\n",
        "craft_tokenizer.save_pretrained(str(CFG.output_dir / \"craft\"))\n",
        "craft_history = craft_trainer.state.log_history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "616c0034",
      "metadata": {},
      "source": [
        "## 9. Compare BLEU across base, SFT, and CRAFT runs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75761228",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [entry[\"label\"] for entry in results]\n",
        "scores = [entry[\"bleu\"] for entry in results]\n",
        "plt.figure(figsize=(6, 4))\n",
        "bars = plt.bar(labels, scores, color=[\"#7f8c8d\", \"#2980b9\", \"#27ae60\"])\n",
        "plt.ylabel(\"sacreBLEU\")\n",
        "plt.title(\"Flores sacreBLEU comparison\")\n",
        "plt.ylim(0, max(scores) + 2)\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.2, f\"{score:.2f}\", ha=\"center\")\n",
        "plt.show()\n",
        "\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb4d1bd3",
      "metadata": {},
      "source": [
        "## 10. Inspect CRAFT training metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90f8771",
      "metadata": {},
      "outputs": [],
      "source": [
        "craft_logs = [entry for entry in craft_history if \"loss/craft_total\" in entry]\n",
        "if craft_logs:\n",
        "    steps = [entry.get(\"step\", idx) for idx, entry in enumerate(craft_logs)]\n",
        "    losses = [entry[\"loss/craft_total\"] for entry in craft_logs]\n",
        "    contrastive = [entry.get(\"metrics/craft_contrastive_accuracy\") for entry in craft_logs]\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(steps, losses, label=\"CRAFT total loss\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"CRAFT loss trajectory\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(steps, contrastive, label=\"Contrastive accuracy\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Contrastive metric\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No craft logs captured.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9464a3",
      "metadata": {},
      "source": [
        "## 11. Summarise insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279297e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = {\n",
        "    \"bleu_scores\": {entry[\"label\"]: entry[\"bleu\"] for entry in results},\n",
        "    \"best_run\": max(results, key=lambda item: item[\"bleu\"]),\n",
        "    \"craft_final_metrics\": getattr(craft_trainer, \"craft_metrics\", {}),\n",
        "    \"length_strategy\": CFG.craft_length_strategy,\n",
        "    \"contrastive_batch_size\": CFG.craft_contrastive_batch_size,\n",
        "}\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8746c982",
      "metadata": {},
      "source": [
        "## 12. Optional: release GPU memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be04d73",
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_model(craft_model)\n",
        "del craft_tokenizer\n",
        "torch.cuda.empty_cache()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
